<!--
 * @description: 
 * @version: 
 * @Author: zwy
 * @Date: 2023-07-11 18:09:05
 * @LastEditors: zwy
 * @LastEditTime: 2023-07-11 18:38:32
-->
## 1、针对动态维度，需要修改 ultralytics/yolo/engine/exporter.py 文件中的代码。第306行
**原文件**
```python
dynamic = self.args.dynamic
if dynamic:
    dynamic = {'images': {0: 'batch', 2: 'height', 3: 'width'}}  # shape(1,3,640,640)
    if isinstance(self.model, SegmentationModel):
        dynamic['output0'] = {0: 'batch', 1: 'anchors'}  # shape(1,25200,85)
        dynamic['output1'] = {0: 'batch', 2: 'mask_height', 3: 'mask_width'}  # shape(1,32,160,160)
    elif isinstance(self.model, DetectionModel):
        dynamic['output0'] = {0: 'batch', 1: 'anchors'}  # shape(1,25200,85)
```

**更改为**
```python
dynamic = True
if dynamic:
    dynamic = {'images': {0: 'batch'}}  # shape(1,3,640,640)
    if isinstance(self.model, SegmentationModel):
        dynamic['output0'] = {0: 'batch', 1: 'anchors'}  # shape(1,25200,85)
        dynamic['output1'] = {0: 'batch'}  # shape(1,32,160,160)
    elif isinstance(self.model, DetectionModel):
        dynamic['output0'] = {0: 'batch', 1: 'anchors'}  # shape(1,25200,85)
```

## 2、将YOLOv8的权重文件导出成onnx文件

```python
from ultralytics import YOLO
# 加载模型

model = YOLO("yolov8s-seg.pt")  # 加载预训练模型（建议用于训练）

# 使用模型
results = model("https://ultralytics.com/images/bus.jpg")  # 对图像进行预测
success = model.export(format="onnx")  # 将模型导出为 ONNX 格式
```

## 3、修改onnx的输出0，这是为了这个框架的输出要求：

YOLOv8s segment 的 output1的形状是：`-1 x 116 x 8400`, 将其改成 `-1 x 8400 x 116`
- -1: dynamic batch 
- 116 -> cx, cy, w, h, 80 class confidence, 32 mask weight
- 8400 -> 3 anchar
只需要运行：

```shell
    python v8trans.py yolov8s-seg.onnx
```

即会生成`-1 x 8400 x 116`的onnx, 保存为yolov8s-seg.transd.onnx